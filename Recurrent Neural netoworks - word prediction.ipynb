{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we will implement a recurrent neural network which is able to classify images. The dataset used here is called MNIST consisting of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from gensim.models import Word2Vec\n",
    "from random import random\n",
    "from nltk import word_tokenize\n",
    "from nltk.translate.bleu_score import sentence_bleu\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the data.\n",
    "train_sentences = [\"The man ate the apple.\", \"Two women running on the beach.\", \"Everybody read this book.\"]\n",
    "val_sentences = [\"A blue bird is singing on the tree.\", \"People were excited about the election.\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lower--case the training sentences, tokenize them and add <SOS> and <EOS> tokens\n",
    "sentences = [[\"<SOS>\"] + word_tokenize(sentence.lower()) + [\"<EOS>\"] for sentence in train_sentences]\n",
    "\n",
    "# Create the vocabulary.\n",
    "word_counts = Counter([word for sentence in sentences for word in sentence])\n",
    "vocabulary = [\"<UNK>\"] + [e[0] for e in word_counts.most_common(2000)]\n",
    "vocabulary_size = len(vocabulary)\n",
    "\n",
    "# Build one-hot embeddings.\n",
    "one_hot_embeddings = np.eye(vocabulary_size)\n",
    "\n",
    "# Build a word-to-index dictionary.\n",
    "word2index = {word:index for index,word in enumerate(vocabulary)}\n",
    "\n",
    "def preprocess_numberize(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence in the form of a string, preprocess it into a list of numbers denoting the index \n",
    "    of each word in the vocabulary.\n",
    "    \"\"\"\n",
    "    tokenized = word_tokenize(sentence.lower())\n",
    "    tokenized = [\"<SOS>\"] + tokenized + [\"<EOS>\"]\n",
    "    numberized = [word2index.get(word) for word in tokenized]\n",
    "    return numberized\n",
    "\n",
    "def preprocess_one_hot(sentence):\n",
    "    \"\"\"\n",
    "    Given a sentence in the form of a string, preprocess it into a a matrix of one-hot vectors corresponding\n",
    "    to each word in the vocabulary.\n",
    "    \"\"\"\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    one_hot_embedded = one_hot_embeddings[numberized]\n",
    "    return one_hot_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<UNK>', '<SOS>', 'the', '.', '<EOS>', 'man', 'ate', 'apple', 'two', 'women', 'running', 'on', 'beach', 'everybody', 'read', 'this', 'book']\n"
     ]
    }
   ],
   "source": [
    "# Let's see what the vocabulary looks like:\n",
    "print(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we can build the LSTM network:\n",
    "class EncoderLSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(EncoderLSTM, self).__init__()\n",
    "        self.hidden_size = hidden_size \n",
    "        self.lstm = nn.LSTM(input_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.softmax = nn.Softmax()\n",
    "        \n",
    "    def forward(self, input, hidden):\n",
    "        #output = F.relu(input)\n",
    "        input = input.view(1,1,-1)\n",
    "        output, hidden = self.lstm(input, hidden)\n",
    "        output = self.out(output[0])\n",
    "        return output, hidden\n",
    "    \n",
    "    def initHidden(self):\n",
    "        h0 = torch.zeros(1, 1, self.hidden_size)\n",
    "        c0 = torch.zeros(1, 1, self.hidden_size)\n",
    "        result = (h0, c0)\n",
    "        if use_cuda:\n",
    "            result = (h0.cuda(), c0.cuda())\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "EncoderLSTM(\n",
       "  (lstm): LSTM(17, 150)\n",
       "  (out): Linear(in_features=150, out_features=17, bias=True)\n",
       "  (softmax): Softmax()\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's see what the model looks like:\n",
    "model = EncoderLSTM(input_size=vocabulary_size, hidden_size=150, output_size=vocabulary_size)\n",
    "if use_cuda:\n",
    "    model = model.cuda()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will write a function to train the network:\n",
    "learning_rate = 0.001\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "def train(target_tensor,\n",
    "         model,\n",
    "         optimizer,\n",
    "         criterion,\n",
    "         embeddings = one_hot_embeddings,\n",
    "         teacher_forcing_ratio = 1.0):\n",
    "    \"\"\"\n",
    "    Given a signle training sample, go through a single step of training.\n",
    "    \"\"\"\n",
    "    loss = 0\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "    input_tensor = torch.FloatTensor(embeddings[word2index['<SOS>']]).unsqueeze(0)\n",
    "    input_tensor = input_tensor.cuda() if use_cuda else input_tensor\n",
    "    target_tensor = target_tensor.view(-1,1)\n",
    "    hidden = model.initHidden()\n",
    "    \n",
    "    use_teacher_forcing = True if np.random.random() < teacher_forcing_ratio else False\n",
    "    \n",
    "    predictions = []\n",
    "    \n",
    "    target_length = target_tensor.size(0)\n",
    "    \n",
    "    if use_teacher_forcing:\n",
    "        # Teacher force:\n",
    "        for i in range(target_length): # ignore first word\n",
    "            output, hidden = model(input_tensor, hidden)\n",
    "            loss += criterion(output, target_tensor[i])\n",
    "            \n",
    "            _, topi = model.softmax(output).data.topk(1) \n",
    "            predictions.append(vocabulary[topi])\n",
    "            \n",
    "            # Set model input to next ground-truth word:\n",
    "            input_tensor = torch.FloatTensor(embeddings[target_tensor[i].data])\n",
    "            input_tensor = input_tensor.cuda() if use_cuda else input_tensor\n",
    "            \n",
    "    else:\n",
    "        # No teacher force:\n",
    "        for i in range(target_length):\n",
    "            output, hidden = model(input_tensor, hidden)\n",
    "            loss += criterion(output, target_tensor[i])\n",
    "            \n",
    "            topv, topi = model.softmax(output).data.topk(1)\n",
    "            predictions.append(vocabulary[topi[0][0]])\n",
    "            \n",
    "            # Set model input to its current output:\n",
    "            input_tensor = torch.FloatTensor([embeddings[topi]])\n",
    "            input_tensor = input_tensor.cuda() if use_cuda else input_tensor\n",
    "            \n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/setareh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:35: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch[1], sentence[1] loss: 0.282\n",
      "epoch[2], sentence[1] loss: 0.279\n",
      "epoch[3], sentence[1] loss: 0.277\n",
      "epoch[4], sentence[1] loss: 0.274\n",
      "epoch[5], sentence[1] loss: 0.271\n",
      "epoch[6], sentence[1] loss: 0.266\n",
      "epoch[7], sentence[1] loss: 0.258\n",
      "epoch[8], sentence[1] loss: 0.246\n",
      "epoch[9], sentence[1] loss: 0.231\n",
      "epoch[10], sentence[1] loss: 0.225\n",
      "epoch[11], sentence[1] loss: 0.225\n",
      "epoch[12], sentence[1] loss: 0.223\n",
      "epoch[13], sentence[1] loss: 0.218\n",
      "epoch[14], sentence[1] loss: 0.215\n",
      "epoch[15], sentence[1] loss: 0.212\n",
      "epoch[16], sentence[1] loss: 0.210\n",
      "epoch[17], sentence[1] loss: 0.207\n",
      "epoch[18], sentence[1] loss: 0.204\n",
      "epoch[19], sentence[1] loss: 0.200\n",
      "epoch[20], sentence[1] loss: 0.197\n",
      "epoch[21], sentence[1] loss: 0.194\n",
      "epoch[22], sentence[1] loss: 0.190\n",
      "epoch[23], sentence[1] loss: 0.187\n",
      "epoch[24], sentence[1] loss: 0.184\n",
      "epoch[25], sentence[1] loss: 0.180\n",
      "epoch[26], sentence[1] loss: 0.176\n",
      "epoch[27], sentence[1] loss: 0.173\n",
      "epoch[28], sentence[1] loss: 0.170\n",
      "epoch[29], sentence[1] loss: 0.166\n",
      "epoch[30], sentence[1] loss: 0.163\n",
      "epoch[31], sentence[1] loss: 0.160\n",
      "epoch[32], sentence[1] loss: 0.157\n",
      "epoch[33], sentence[1] loss: 0.154\n",
      "epoch[34], sentence[1] loss: 0.151\n",
      "epoch[35], sentence[1] loss: 0.148\n",
      "epoch[36], sentence[1] loss: 0.145\n",
      "epoch[37], sentence[1] loss: 0.143\n",
      "epoch[38], sentence[1] loss: 0.140\n",
      "epoch[39], sentence[1] loss: 0.138\n",
      "epoch[40], sentence[1] loss: 0.135\n",
      "epoch[41], sentence[1] loss: 0.133\n",
      "epoch[42], sentence[1] loss: 0.130\n",
      "epoch[43], sentence[1] loss: 0.128\n",
      "epoch[44], sentence[1] loss: 0.125\n",
      "epoch[45], sentence[1] loss: 0.124\n",
      "epoch[46], sentence[1] loss: 0.126\n",
      "epoch[47], sentence[1] loss: 0.124\n",
      "epoch[48], sentence[1] loss: 0.140\n",
      "epoch[49], sentence[1] loss: 0.118\n",
      "epoch[50], sentence[1] loss: 0.127\n",
      "epoch[51], sentence[1] loss: 0.132\n",
      "epoch[52], sentence[1] loss: 0.116\n",
      "epoch[53], sentence[1] loss: 0.115\n",
      "epoch[54], sentence[1] loss: 0.115\n",
      "epoch[55], sentence[1] loss: 0.112\n",
      "epoch[56], sentence[1] loss: 0.110\n",
      "epoch[57], sentence[1] loss: 0.107\n",
      "epoch[58], sentence[1] loss: 0.105\n",
      "epoch[59], sentence[1] loss: 0.104\n",
      "epoch[60], sentence[1] loss: 0.102\n",
      "epoch[61], sentence[1] loss: 0.101\n",
      "epoch[62], sentence[1] loss: 0.099\n",
      "epoch[63], sentence[1] loss: 0.098\n",
      "epoch[64], sentence[1] loss: 0.097\n",
      "epoch[65], sentence[1] loss: 0.096\n",
      "epoch[66], sentence[1] loss: 0.094\n",
      "epoch[67], sentence[1] loss: 0.093\n",
      "epoch[68], sentence[1] loss: 0.092\n",
      "epoch[69], sentence[1] loss: 0.091\n",
      "epoch[70], sentence[1] loss: 0.090\n",
      "epoch[71], sentence[1] loss: 0.088\n",
      "epoch[72], sentence[1] loss: 0.087\n",
      "epoch[73], sentence[1] loss: 0.086\n",
      "epoch[74], sentence[1] loss: 0.085\n",
      "epoch[75], sentence[1] loss: 0.084\n",
      "epoch[76], sentence[1] loss: 0.083\n",
      "epoch[77], sentence[1] loss: 0.082\n",
      "epoch[78], sentence[1] loss: 0.080\n",
      "epoch[79], sentence[1] loss: 0.079\n",
      "epoch[80], sentence[1] loss: 0.078\n",
      "epoch[81], sentence[1] loss: 0.077\n",
      "epoch[82], sentence[1] loss: 0.076\n",
      "epoch[83], sentence[1] loss: 0.075\n",
      "epoch[84], sentence[1] loss: 0.075\n",
      "epoch[85], sentence[1] loss: 0.074\n",
      "epoch[86], sentence[1] loss: 0.073\n",
      "epoch[87], sentence[1] loss: 0.072\n",
      "epoch[88], sentence[1] loss: 0.071\n",
      "epoch[89], sentence[1] loss: 0.070\n",
      "epoch[90], sentence[1] loss: 0.069\n",
      "epoch[91], sentence[1] loss: 0.068\n",
      "epoch[92], sentence[1] loss: 0.068\n",
      "epoch[93], sentence[1] loss: 0.067\n",
      "epoch[94], sentence[1] loss: 0.066\n",
      "epoch[95], sentence[1] loss: 0.065\n",
      "epoch[96], sentence[1] loss: 0.064\n",
      "epoch[97], sentence[1] loss: 0.064\n",
      "epoch[98], sentence[1] loss: 0.063\n",
      "epoch[99], sentence[1] loss: 0.062\n",
      "epoch[100], sentence[1] loss: 0.061\n"
     ]
    }
   ],
   "source": [
    "# Let's train the network:\n",
    "model.train()\n",
    "num_epochs = 100\n",
    "teacher_forcing_ratio = 1.0\n",
    "for epoch in range(num_epochs):\n",
    "    total_loss = 0\n",
    "    for i, sentence in enumerate(train_sentences):\n",
    "        '''\n",
    "        if epoch > 200:\n",
    "            teacher_forcing_ratio = 0.5\n",
    "        elif epoch > 800:\n",
    "            teacher_forcing_ratio = 0.2\n",
    "        elif epoch > 1500:\n",
    "            teacher_forcing_ratio = 0.0\n",
    "        '''\n",
    "        word_indices = preprocess_numberize(sentence.lower())\n",
    "        target_tensor = torch.LongTensor(word_indices[1:])\n",
    "        target_tensor = target_tensor.cuda() if use_cuda else target_tensor # start from first word instead of <SOS>\n",
    "        loss = train(target_tensor, model, optimizer, criterion, teacher_forcing_ratio=teacher_forcing_ratio)\n",
    "        total_loss += loss\n",
    "        if i % 10 == 0:\n",
    "            print('epoch[%d], sentence[%d] loss: %.3f' % (epoch+1, i+1, total_loss/10))\n",
    "            total_loss = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The man ate the apple.\n",
      "['<SOS>', 'the', 'man', 'ate']\n",
      "['the', 'apple', '.', '<EOS>']\n",
      "Two women running on the beach.\n",
      "['<SOS>', 'two', 'women', 'running']\n",
      "['on', 'the', 'beach', '.', '<EOS>']\n",
      "Everybody read this book.\n",
      "['<SOS>', 'everybody', 'read']\n",
      "['this', 'book', '.', '<EOS>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/setareh/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:27: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "# Let's test the training:\n",
    "# to do so, we will input first half of words of each sentence in train_sentences and output the second half\n",
    "model.eval()\n",
    "for sentence in train_sentences:\n",
    "    print(sentence)\n",
    "    '''\n",
    "    one_hot_embedded = preprocess_one_hot(sentence)\n",
    "    input_tensor = input_tensor.cuda() if use_cuda else input_tensor\n",
    "    input_tensor = torch.FloatTensor(one_hot_embedded)\n",
    "    hidden = model.initHidden()\n",
    "    input_length = len(input_tensor)\n",
    "    '''\n",
    "    numberized = preprocess_numberize(sentence)\n",
    "    \n",
    "    out_sentence = []\n",
    "    in_sentence = []\n",
    "    hidden = model.initHidden()\n",
    "    for i in range(len(numberized)//2):\n",
    "        in_sentence.append(vocabulary[numberized[i]])\n",
    "        input_tensor = torch.FloatTensor([one_hot_embeddings[numberized[i]]])\n",
    "        input_tensor = input_tensor.cuda() if use_cuda else input_tensor\n",
    "        output, hidden = model(input_tensor, hidden)\n",
    "        #topv, topi = model.softmax(output).data.topk(1)\n",
    "        #out_sentence.append(vocabulary[topi[0][0]])\n",
    "        \n",
    "    while len(out_sentence) == 0 or out_sentence[-1] != '<EOS>':\n",
    "        topv, topi = model.softmax(output).data.topk(1)\n",
    "        out_sentence.append(vocabulary[topi[0][0]])\n",
    "\n",
    "        input_tensor = torch.FloatTensor([one_hot_embeddings[topi]])\n",
    "        input_tensor = input_tensor.cuda() if use_cuda else input_tensor\n",
    "        output, hidden = model(input_tensor, hidden)\n",
    "    print(in_sentence)\n",
    "    print(out_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
